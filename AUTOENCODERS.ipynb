{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('/home/nilesh/Desktop/MY FILES/DEEP LEARNING COURSE/7. Boltzmann_Machines/Boltzmann_Machines/ml-1m/movies.dat' , delimiter = '::' , header = None , engine = 'python' , encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('/home/nilesh/Desktop/MY FILES/DEEP LEARNING COURSE/7. Boltzmann_Machines/Boltzmann_Machines/ml-1m/users.dat' , delimiter = '::' , header = None , engine = 'python' , encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('/home/nilesh/Desktop/MY FILES/DEEP LEARNING COURSE/7. Boltzmann_Machines/Boltzmann_Machines/ml-1m/ratings.dat' , delimiter = '::' , header = None , engine = 'python' , encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(pd.read_csv('/home/nilesh/Desktop/MY FILES/DEEP LEARNING COURSE/7. Boltzmann_Machines/Boltzmann_Machines/ml-100k/u1.base' , delimiter='\\t') , dtype='int')\n",
    "testing_set = np.array(pd.read_csv('/home/nilesh/Desktop/MY FILES/DEEP LEARNING COURSE/7. Boltzmann_Machines/Boltzmann_Machines/ml-100k/u1.test' , delimiter='\\t') , dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = int(max(max(training_set[:,0]),max(testing_set[:,0])))\n",
    "total_movies = int(max(max(training_set[:,1]),max(testing_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data):\n",
    "    ret_data = []\n",
    "    for i in range(1,total_users+1):\n",
    "        ratings = np.zeros(total_movies)\n",
    "        for j in range(0,data.shape[0]):\n",
    "            if data[j][0] == i:\n",
    "                ratings[data[j][1] - 1] = data[j][2] \n",
    "        ret_data.append(list(ratings))\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_new = convert_data(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set_new = convert_data(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = torch.FloatTensor(training_set_new)\n",
    "xtest = torch.FloatTensor(testing_set_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self , ):\n",
    "        super(SAE,self).__init__()\n",
    "        self.fc1 = nn.Linear(total_movies , 20)\n",
    "        self.fc2 = nn.Linear(20 , 10)\n",
    "        self.fc3 = nn.Linear(10 , 20)\n",
    "        self.fc4 = nn.Linear(20 , total_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward_propagation(self , x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters() , lr = 0.01 ,weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1 loss :  tensor(1.7537)\n",
      "epoch :  2 loss :  tensor(1.0962)\n",
      "epoch :  3 loss :  tensor(1.0531)\n",
      "epoch :  4 loss :  tensor(1.0384)\n",
      "epoch :  5 loss :  tensor(1.0309)\n",
      "epoch :  6 loss :  tensor(1.0266)\n",
      "epoch :  7 loss :  tensor(1.0237)\n",
      "epoch :  8 loss :  tensor(1.0220)\n",
      "epoch :  9 loss :  tensor(1.0207)\n",
      "epoch :  10 loss :  tensor(1.0196)\n",
      "epoch :  11 loss :  tensor(1.0187)\n",
      "epoch :  12 loss :  tensor(1.0182)\n",
      "epoch :  13 loss :  tensor(1.0177)\n",
      "epoch :  14 loss :  tensor(1.0174)\n",
      "epoch :  15 loss :  tensor(1.0173)\n",
      "epoch :  16 loss :  tensor(1.0168)\n",
      "epoch :  17 loss :  tensor(1.0167)\n",
      "epoch :  18 loss :  tensor(1.0164)\n",
      "epoch :  19 loss :  tensor(1.0164)\n",
      "epoch :  20 loss :  tensor(1.0162)\n",
      "epoch :  21 loss :  tensor(1.0160)\n",
      "epoch :  22 loss :  tensor(1.0160)\n",
      "epoch :  23 loss :  tensor(1.0156)\n",
      "epoch :  24 loss :  tensor(1.0156)\n",
      "epoch :  25 loss :  tensor(1.0155)\n",
      "epoch :  26 loss :  tensor(1.0156)\n",
      "epoch :  27 loss :  tensor(1.0154)\n",
      "epoch :  28 loss :  tensor(1.0152)\n",
      "epoch :  29 loss :  tensor(1.0126)\n",
      "epoch :  30 loss :  tensor(1.0110)\n",
      "epoch :  31 loss :  tensor(1.0110)\n",
      "epoch :  32 loss :  tensor(1.0084)\n",
      "epoch :  33 loss :  tensor(1.0083)\n",
      "epoch :  34 loss :  tensor(1.0040)\n",
      "epoch :  35 loss :  tensor(1.0040)\n",
      "epoch :  36 loss :  tensor(1.0014)\n",
      "epoch :  37 loss :  tensor(0.9999)\n",
      "epoch :  38 loss :  tensor(0.9962)\n",
      "epoch :  39 loss :  tensor(0.9953)\n",
      "epoch :  40 loss :  tensor(0.9930)\n",
      "epoch :  41 loss :  tensor(0.9943)\n",
      "epoch :  42 loss :  tensor(0.9927)\n",
      "epoch :  43 loss :  tensor(0.9898)\n",
      "epoch :  44 loss :  tensor(0.9899)\n",
      "epoch :  45 loss :  tensor(0.9872)\n",
      "epoch :  46 loss :  tensor(0.9827)\n",
      "epoch :  47 loss :  tensor(0.9855)\n",
      "epoch :  48 loss :  tensor(0.9836)\n",
      "epoch :  49 loss :  tensor(0.9864)\n",
      "epoch :  50 loss :  tensor(0.9828)\n",
      "epoch :  51 loss :  tensor(0.9846)\n",
      "epoch :  52 loss :  tensor(0.9817)\n",
      "epoch :  53 loss :  tensor(0.9783)\n",
      "epoch :  54 loss :  tensor(0.9750)\n",
      "epoch :  55 loss :  tensor(0.9751)\n",
      "epoch :  56 loss :  tensor(0.9719)\n",
      "epoch :  57 loss :  tensor(0.9702)\n",
      "epoch :  58 loss :  tensor(0.9686)\n",
      "epoch :  59 loss :  tensor(0.9709)\n",
      "epoch :  60 loss :  tensor(0.9706)\n",
      "epoch :  61 loss :  tensor(0.9705)\n",
      "epoch :  62 loss :  tensor(0.9669)\n",
      "epoch :  63 loss :  tensor(0.9617)\n",
      "epoch :  64 loss :  tensor(0.9627)\n",
      "epoch :  65 loss :  tensor(0.9648)\n",
      "epoch :  66 loss :  tensor(0.9612)\n",
      "epoch :  67 loss :  tensor(0.9640)\n",
      "epoch :  68 loss :  tensor(0.9607)\n",
      "epoch :  69 loss :  tensor(0.9609)\n",
      "epoch :  70 loss :  tensor(0.9596)\n",
      "epoch :  71 loss :  tensor(0.9580)\n",
      "epoch :  72 loss :  tensor(0.9566)\n",
      "epoch :  73 loss :  tensor(0.9542)\n",
      "epoch :  74 loss :  tensor(0.9572)\n",
      "epoch :  75 loss :  tensor(0.9616)\n",
      "epoch :  76 loss :  tensor(0.9544)\n",
      "epoch :  77 loss :  tensor(0.9528)\n",
      "epoch :  78 loss :  tensor(0.9513)\n",
      "epoch :  79 loss :  tensor(0.9521)\n",
      "epoch :  80 loss :  tensor(0.9476)\n",
      "epoch :  81 loss :  tensor(0.9469)\n",
      "epoch :  82 loss :  tensor(0.9456)\n",
      "epoch :  83 loss :  tensor(0.9459)\n",
      "epoch :  84 loss :  tensor(0.9456)\n",
      "epoch :  85 loss :  tensor(0.9454)\n",
      "epoch :  86 loss :  tensor(0.9427)\n",
      "epoch :  87 loss :  tensor(0.9446)\n",
      "epoch :  88 loss :  tensor(0.9417)\n",
      "epoch :  89 loss :  tensor(0.9423)\n",
      "epoch :  90 loss :  tensor(0.9405)\n",
      "epoch :  91 loss :  tensor(0.9402)\n",
      "epoch :  92 loss :  tensor(0.9396)\n",
      "epoch :  93 loss :  tensor(0.9396)\n",
      "epoch :  94 loss :  tensor(0.9384)\n",
      "epoch :  95 loss :  tensor(0.9388)\n",
      "epoch :  96 loss :  tensor(0.9367)\n",
      "epoch :  97 loss :  tensor(0.9368)\n",
      "epoch :  98 loss :  tensor(0.9353)\n",
      "epoch :  99 loss :  tensor(0.9357)\n",
      "epoch :  100 loss :  tensor(0.9345)\n",
      "epoch :  101 loss :  tensor(0.9345)\n",
      "epoch :  102 loss :  tensor(0.9338)\n",
      "epoch :  103 loss :  tensor(0.9325)\n",
      "epoch :  104 loss :  tensor(0.9317)\n",
      "epoch :  105 loss :  tensor(0.9360)\n",
      "epoch :  106 loss :  tensor(0.9349)\n",
      "epoch :  107 loss :  tensor(0.9339)\n",
      "epoch :  108 loss :  tensor(0.9332)\n",
      "epoch :  109 loss :  tensor(0.9332)\n",
      "epoch :  110 loss :  tensor(0.9327)\n",
      "epoch :  111 loss :  tensor(0.9326)\n",
      "epoch :  112 loss :  tensor(0.9311)\n",
      "epoch :  113 loss :  tensor(0.9313)\n",
      "epoch :  114 loss :  tensor(0.9303)\n",
      "epoch :  115 loss :  tensor(0.9301)\n",
      "epoch :  116 loss :  tensor(0.9293)\n",
      "epoch :  117 loss :  tensor(0.9292)\n",
      "epoch :  118 loss :  tensor(0.9282)\n",
      "epoch :  119 loss :  tensor(0.9278)\n",
      "epoch :  120 loss :  tensor(0.9264)\n",
      "epoch :  121 loss :  tensor(0.9276)\n",
      "epoch :  122 loss :  tensor(0.9268)\n",
      "epoch :  123 loss :  tensor(0.9276)\n",
      "epoch :  124 loss :  tensor(0.9259)\n",
      "epoch :  125 loss :  tensor(0.9258)\n",
      "epoch :  126 loss :  tensor(0.9246)\n",
      "epoch :  127 loss :  tensor(0.9252)\n",
      "epoch :  128 loss :  tensor(0.9240)\n",
      "epoch :  129 loss :  tensor(0.9244)\n",
      "epoch :  130 loss :  tensor(0.9242)\n",
      "epoch :  131 loss :  tensor(0.9249)\n",
      "epoch :  132 loss :  tensor(0.9242)\n",
      "epoch :  133 loss :  tensor(0.9252)\n",
      "epoch :  134 loss :  tensor(0.9232)\n",
      "epoch :  135 loss :  tensor(0.9249)\n",
      "epoch :  136 loss :  tensor(0.9279)\n",
      "epoch :  137 loss :  tensor(0.9324)\n",
      "epoch :  138 loss :  tensor(0.9299)\n",
      "epoch :  139 loss :  tensor(0.9306)\n",
      "epoch :  140 loss :  tensor(0.9275)\n",
      "epoch :  141 loss :  tensor(0.9273)\n",
      "epoch :  142 loss :  tensor(0.9254)\n",
      "epoch :  143 loss :  tensor(0.9264)\n",
      "epoch :  144 loss :  tensor(0.9242)\n",
      "epoch :  145 loss :  tensor(0.9254)\n",
      "epoch :  146 loss :  tensor(0.9247)\n",
      "epoch :  147 loss :  tensor(0.9248)\n",
      "epoch :  148 loss :  tensor(0.9231)\n",
      "epoch :  149 loss :  tensor(0.9245)\n",
      "epoch :  150 loss :  tensor(0.9226)\n",
      "epoch :  151 loss :  tensor(0.9236)\n",
      "epoch :  152 loss :  tensor(0.9215)\n",
      "epoch :  153 loss :  tensor(0.9232)\n",
      "epoch :  154 loss :  tensor(0.9211)\n",
      "epoch :  155 loss :  tensor(0.9221)\n",
      "epoch :  156 loss :  tensor(0.9204)\n",
      "epoch :  157 loss :  tensor(0.9213)\n",
      "epoch :  158 loss :  tensor(0.9194)\n",
      "epoch :  159 loss :  tensor(0.9204)\n",
      "epoch :  160 loss :  tensor(0.9188)\n",
      "epoch :  161 loss :  tensor(0.9209)\n",
      "epoch :  162 loss :  tensor(0.9188)\n",
      "epoch :  163 loss :  tensor(0.9200)\n",
      "epoch :  164 loss :  tensor(0.9184)\n",
      "epoch :  165 loss :  tensor(0.9196)\n",
      "epoch :  166 loss :  tensor(0.9181)\n",
      "epoch :  167 loss :  tensor(0.9196)\n",
      "epoch :  168 loss :  tensor(0.9180)\n",
      "epoch :  169 loss :  tensor(0.9186)\n",
      "epoch :  170 loss :  tensor(0.9172)\n",
      "epoch :  171 loss :  tensor(0.9188)\n",
      "epoch :  172 loss :  tensor(0.9172)\n",
      "epoch :  173 loss :  tensor(0.9182)\n",
      "epoch :  174 loss :  tensor(0.9177)\n",
      "epoch :  175 loss :  tensor(0.9180)\n",
      "epoch :  176 loss :  tensor(0.9163)\n",
      "epoch :  177 loss :  tensor(0.9176)\n",
      "epoch :  178 loss :  tensor(0.9163)\n",
      "epoch :  179 loss :  tensor(0.9173)\n",
      "epoch :  180 loss :  tensor(0.9154)\n",
      "epoch :  181 loss :  tensor(0.9168)\n",
      "epoch :  182 loss :  tensor(0.9156)\n",
      "epoch :  183 loss :  tensor(0.9165)\n",
      "epoch :  184 loss :  tensor(0.9151)\n",
      "epoch :  185 loss :  tensor(0.9162)\n",
      "epoch :  186 loss :  tensor(0.9147)\n",
      "epoch :  187 loss :  tensor(0.9159)\n",
      "epoch :  188 loss :  tensor(0.9145)\n",
      "epoch :  189 loss :  tensor(0.9157)\n",
      "epoch :  190 loss :  tensor(0.9144)\n",
      "epoch :  191 loss :  tensor(0.9154)\n",
      "epoch :  192 loss :  tensor(0.9139)\n",
      "epoch :  193 loss :  tensor(0.9152)\n",
      "epoch :  194 loss :  tensor(0.9138)\n",
      "epoch :  195 loss :  tensor(0.9145)\n",
      "epoch :  196 loss :  tensor(0.9133)\n",
      "epoch :  197 loss :  tensor(0.9141)\n",
      "epoch :  198 loss :  tensor(0.9130)\n",
      "epoch :  199 loss :  tensor(0.9138)\n",
      "epoch :  200 loss :  tensor(0.9126)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1 , nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    ctr = 0.\n",
    "    for user in range(total_users):\n",
    "        inp_ = Variable(xtrain[user]).unsqueeze(0)\n",
    "        target = inp_.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            out_ = sae.forward_propagation(inp_)\n",
    "            target.require_grad = False\n",
    "            out_[target == 0] = 0\n",
    "            loss = criterion(out_ , target)\n",
    "            mean_corrector = total_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt((loss.data[0])*(mean_corrector))\n",
    "            ctr += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch : ' , epoch , 'loss : ' , str(train_loss/ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  tensor(0.9512)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "ctr = 0.\n",
    "for user in range(total_users):\n",
    "    inp_ = Variable(xtrain[user]).unsqueeze(0)\n",
    "    target = Variable(xtest[user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        out_ = sae.forward_propagation(inp_)\n",
    "        target.require_grad = False\n",
    "        out_[target == 0] = 0\n",
    "        loss = criterion(out_ , target)\n",
    "        mean_corrector = total_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt((loss.data[0])*(mean_corrector))\n",
    "        ctr += 1.\n",
    "print('loss : ' , str(test_loss/ctr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
